# -*- coding: utf-8 -*-
"""KendrickVDrake.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NI2ClwN3dD1UigbM34uMXAbNtmJ3WO6i
"""

import nltk
nltk.download('gutenberg')
nltk.download("book", quiet=True)
nltk.download("punkt", quiet=True)
nltk.download('punkt_tab', quiet=True)
nltk.download('stopwords', quiet=True)
from nltk.book import *
import spacy
from nltk import FreqDist
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

##If you're using a Colab Noteboook like I did, you will need to upload your txt files into the workspace
with open("/content/kenny.txt") as k:
  kenny = k.read()
with open("/content/drake.txt") as d:
  drake = d.read()

stop_words = set(stopwords.words('english'))

# Frequency distribution for Kenny
kenny_tokens = word_tokenize(kenny.lower())
kenny_tokens_filtered = [w for w in kenny_tokens if w not in stop_words and w != ',' and w.isalnum()]
kenny_fd = FreqDist(kenny_tokens_filtered)
print("Frequency Distribution for Kenny:")
print(kenny_fd.most_common(10))

# Frequency distribution for Drake
drake_tokens = word_tokenize(drake.lower())
drake_tokens_filtered = [w for w in drake_tokens if w not in stop_words and w != ',' and w.isalnum()]
drake_fd = FreqDist(drake_tokens_filtered)
print("\nFrequency Distribution for Drake:")
print(drake_fd.most_common(10))

kenny_vocab_size = len(set(kenny_tokens_filtered))
drake_vocab_size = len(set(drake_tokens_filtered))
print(f"Kendrick's vocabulary size: {kenny_vocab_size}")
print(f"Drake's vocabulary size: {drake_vocab_size}")

if kenny_vocab_size > drake_vocab_size:
    print("Kendrick has a wider vocabulary.")
elif drake_vocab_size > kenny_vocab_size:
    print("Drake has a wider vocabulary.")
else:
    print("Kendrick and Drake have the same vocabulary size.")